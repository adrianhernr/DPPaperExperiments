{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Exp2CiteSeerTrainingSet.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMrVPx0PtzdFD9vLg3zKdEa"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fYvxMt6P-g8e","executionInfo":{"status":"ok","timestamp":1644414184099,"user_tz":-60,"elapsed":11138,"user":{"displayName":"Adrian Hernandez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjcBgwUm3IOIr2eMtDO7J2Z0-Ezy0aPy2YzerW1FA=s64","userId":"05338976519150686624"}},"outputId":"505688c4-90cc-455e-f117-01a456c30970"},"source":["#Check the PyTorch and Cuda version\n","!python -c \"import torch; print(torch.__version__)\"\n","!python -c \"import torch; print(torch.version.cuda)\""],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["1.10.0+cu111\n","11.1\n"]}]},{"cell_type":"code","metadata":{"id":"ICFCAiNp-qHq"},"source":["!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-1.10.0+cu111.html\n","!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-1.10.0+cu111.html\n","!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git\n","!pip install torch-cluster -f https://data.pyg.org/whl/torch-1.10.0+cu111.html\n","!pip install torch-spline-conv -f https://pytorch-geometric.com/whl/torch-1.10.0+cu111.html"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LgzQTkyL-4GJ","executionInfo":{"status":"ok","timestamp":1644414252400,"user_tz":-60,"elapsed":4750,"user":{"displayName":"Adrian Hernandez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjcBgwUm3IOIr2eMtDO7J2Z0-Ezy0aPy2YzerW1FA=s64","userId":"05338976519150686624"}},"outputId":"d0a8470e-0a41-4e3b-ffac-997941527e07"},"source":["#First data characteristics\n","from torch_geometric.datasets import Planetoid\n","from torch_geometric.transforms import NormalizeFeatures\n","\n","dataset = Planetoid(root='/tmp/CiteSeer', name='CiteSeer',transform=NormalizeFeatures())\n","\n","data = dataset[0]\n","print(data)\n","\n","print(f'Number of nodes: {data.num_nodes}')\n","print(f'Nodes features: {data.num_node_features}')\n","print(f'Number of classes: {dataset.num_classes}')\n","print(f'Number of edges: {data.num_edges}')\n","print(f'Avarage degree: {data.num_edges / data.num_nodes:.2f}')\n","print(f'Training nodes: {data.train_mask.sum()}')\n","print(f'Validation nodes: {data.val_mask.sum()}')\n","print(f'Test nodes: {data.test_mask.sum()}')\n","print(f'Isolated nodes: {data.has_isolated_nodes()}')\n","print(f'Loops: {data.has_self_loops()}')\n","print(f'Is undirected: {data.is_undirected()}')"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.x\n","Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.tx\n","Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.allx\n","Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.y\n","Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.ty\n","Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.ally\n","Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.graph\n","Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.test.index\n","Processing...\n"]},{"output_type":"stream","name":"stdout","text":["Data(x=[3327, 3703], edge_index=[2, 9104], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327])\n","Number of nodes: 3327\n","Nodes features: 3703\n","Number of classes: 6\n","Number of edges: 9104\n","Avarage degree: 2.74\n","Training nodes: 120\n","Validation nodes: 500\n","Test nodes: 1000\n","Isolated nodes: True\n","Loops: False\n","Is undirected: True\n"]},{"output_type":"stream","name":"stderr","text":["Done!\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VAplR-rc-TAA","executionInfo":{"status":"ok","timestamp":1644331691135,"user_tz":-60,"elapsed":227,"user":{"displayName":"Adrian Hernandez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjcBgwUm3IOIr2eMtDO7J2Z0-Ezy0aPy2YzerW1FA=s64","userId":"05338976519150686624"}},"outputId":"553fca39-16cb-4753-c6fa-4f990e9818a2"},"source":["#Viewing the training mask\n","data.train_mask[100:130]\n"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n","         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n","        False, False, False, False, False, False, False, False, False, False])"]},"metadata":{},"execution_count":41}]},{"cell_type":"markdown","metadata":{"id":"aOesxumADWtu"},"source":["**Model with GCN and with a different training set**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3Wt9BL5YBUlg","executionInfo":{"status":"ok","timestamp":1644331694458,"user_tz":-60,"elapsed":251,"user":{"displayName":"Adrian Hernandez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjcBgwUm3IOIr2eMtDO7J2Z0-Ezy0aPy2YzerW1FA=s64","userId":"05338976519150686624"}},"outputId":"2962df3b-d054-4b51-a746-25cc02bdd60c"},"source":["import torch\n","from torch.nn import Linear\n","import torch.nn.functional as F\n","from torch_geometric.nn import GCNConv\n","\n","\n","\n","class GCN(torch.nn.Module):\n","    def __init__(self, hidden_channels):\n","        super(GCN, self).__init__()\n","        torch.manual_seed(1234567)\n","        self.conv1 = GCNConv(dataset.num_features, hidden_channels)\n","        self.conv2 = GCNConv(hidden_channels, dataset.num_classes)\n","\n","    def forward(self, x, edge_index):\n","        x = self.conv1(x, edge_index)\n","        x = x.relu()\n","        x = F.dropout(x, p=0.5, training=self.training)\n","        x = self.conv2(x, edge_index)\n","        return x\n","\n","model = GCN(hidden_channels=16)\n","\n","def model_summary(model):\n","    \n","    model_params_list = list(model.named_parameters())\n","    print(\"----------------------------------------------------------------\")\n","    line_new = \"{:>20}  {:>25} {:>15}\".format(\"Layer.Parameter\", \"Param Tensor Shape\", \"Param #\")\n","    print(line_new)\n","    print(\"----------------------------------------------------------------\")\n","    for elem in model_params_list:\n","        p_name = elem[0] \n","        p_shape = list(elem[1].size())\n","        p_count = torch.tensor(elem[1].size()).prod().item()\n","        line_new = \"{:>20}  {:>25} {:>15}\".format(p_name, str(p_shape), str(p_count))\n","        print(line_new)\n","    print(\"----------------------------------------------------------------\")\n","    total_params = sum([param.nelement() for param in model.parameters()])\n","    print(\"Total params:\", total_params)\n","    num_trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n","    print(\"Trainable params:\", num_trainable_params)\n","    print(\"Non-trainable params:\", total_params - num_trainable_params)\n","\n","model_summary(model)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["----------------------------------------------------------------\n","     Layer.Parameter         Param Tensor Shape         Param #\n","----------------------------------------------------------------\n","          conv1.bias                       [16]              16\n","    conv1.lin.weight                 [16, 3703]           59248\n","          conv2.bias                        [6]               6\n","    conv2.lin.weight                    [6, 16]              96\n","----------------------------------------------------------------\n","Total params: 59366\n","Trainable params: 59366\n","Non-trainable params: 0\n"]}]},{"cell_type":"code","metadata":{"id":"X1JRgje7BZNi","colab":{"base_uri":"https://localhost:8080/","height":300},"executionInfo":{"status":"ok","timestamp":1644331706229,"user_tz":-60,"elapsed":8149,"user":{"displayName":"Adrian Hernandez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjcBgwUm3IOIr2eMtDO7J2Z0-Ezy0aPy2YzerW1FA=s64","userId":"05338976519150686624"}},"outputId":"a661534f-947d-49ae-e970-5c54d0f783b1"},"source":["from IPython.display import Javascript  # Restrict height of output cell.\n","display(Javascript('''google.colab.output.setIframeHeight(0, true, {maxHeight: 300})'''))\n","\n","model = GCN(hidden_channels=16)\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n","criterion = torch.nn.CrossEntropyLoss()\n","\n","def train():\n","      model.train()\n","      optimizer.zero_grad()  # Clear gradients.\n","      out = model(data.x, data.edge_index)  # Perform a single forward pass.\n","      loss = criterion(out[0:1500], data.y[0:1500])  # Compute the loss\n","      loss.backward()  # Derive gradients.\n","      optimizer.step()  # Update parameters based on gradients.\n","      return loss\n","\n","def test():\n","      model.eval()\n","      out = model(data.x, data.edge_index)\n","      pred = out.argmax(dim=1)  # Use the class with highest probability.\n","      test_correct = pred[data.test_mask] == data.y[data.test_mask]  # Check against ground-truth labels.\n","      test_acc = int(test_correct.sum()) / int(data.test_mask.sum())  # Derive ratio of correct predictions.\n","      return test_acc\n","\n","\n","for epoch in range(1, 201):\n","    loss = train()\n","    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}')"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/javascript":["google.colab.output.setIframeHeight(0, true, {maxHeight: 300})"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch: 001, Loss: 1.7915\n","Epoch: 002, Loss: 1.7850\n","Epoch: 003, Loss: 1.7777\n","Epoch: 004, Loss: 1.7700\n","Epoch: 005, Loss: 1.7634\n","Epoch: 006, Loss: 1.7536\n","Epoch: 007, Loss: 1.7481\n","Epoch: 008, Loss: 1.7392\n","Epoch: 009, Loss: 1.7309\n","Epoch: 010, Loss: 1.7262\n","Epoch: 011, Loss: 1.7209\n","Epoch: 012, Loss: 1.7114\n","Epoch: 013, Loss: 1.7065\n","Epoch: 014, Loss: 1.7060\n","Epoch: 015, Loss: 1.6936\n","Epoch: 016, Loss: 1.6911\n","Epoch: 017, Loss: 1.6839\n","Epoch: 018, Loss: 1.6796\n","Epoch: 019, Loss: 1.6719\n","Epoch: 020, Loss: 1.6697\n","Epoch: 021, Loss: 1.6622\n","Epoch: 022, Loss: 1.6634\n","Epoch: 023, Loss: 1.6547\n","Epoch: 024, Loss: 1.6433\n","Epoch: 025, Loss: 1.6414\n","Epoch: 026, Loss: 1.6343\n","Epoch: 027, Loss: 1.6271\n","Epoch: 028, Loss: 1.6317\n","Epoch: 029, Loss: 1.6128\n","Epoch: 030, Loss: 1.6076\n","Epoch: 031, Loss: 1.5998\n","Epoch: 032, Loss: 1.5960\n","Epoch: 033, Loss: 1.5888\n","Epoch: 034, Loss: 1.5862\n","Epoch: 035, Loss: 1.5743\n","Epoch: 036, Loss: 1.5606\n","Epoch: 037, Loss: 1.5554\n","Epoch: 038, Loss: 1.5511\n","Epoch: 039, Loss: 1.5383\n","Epoch: 040, Loss: 1.5355\n","Epoch: 041, Loss: 1.5242\n","Epoch: 042, Loss: 1.5210\n","Epoch: 043, Loss: 1.5092\n","Epoch: 044, Loss: 1.4958\n","Epoch: 045, Loss: 1.4937\n","Epoch: 046, Loss: 1.4812\n","Epoch: 047, Loss: 1.4776\n","Epoch: 048, Loss: 1.4653\n","Epoch: 049, Loss: 1.4660\n","Epoch: 050, Loss: 1.4527\n","Epoch: 051, Loss: 1.4394\n","Epoch: 052, Loss: 1.4370\n","Epoch: 053, Loss: 1.4266\n","Epoch: 054, Loss: 1.4235\n","Epoch: 055, Loss: 1.4050\n","Epoch: 056, Loss: 1.3980\n","Epoch: 057, Loss: 1.3927\n","Epoch: 058, Loss: 1.3941\n","Epoch: 059, Loss: 1.3828\n","Epoch: 060, Loss: 1.3653\n","Epoch: 061, Loss: 1.3603\n","Epoch: 062, Loss: 1.3541\n","Epoch: 063, Loss: 1.3542\n","Epoch: 064, Loss: 1.3408\n","Epoch: 065, Loss: 1.3324\n","Epoch: 066, Loss: 1.3359\n","Epoch: 067, Loss: 1.3210\n","Epoch: 068, Loss: 1.2923\n","Epoch: 069, Loss: 1.3167\n","Epoch: 070, Loss: 1.2965\n","Epoch: 071, Loss: 1.2845\n","Epoch: 072, Loss: 1.2842\n","Epoch: 073, Loss: 1.2746\n","Epoch: 074, Loss: 1.2640\n","Epoch: 075, Loss: 1.2634\n","Epoch: 076, Loss: 1.2521\n","Epoch: 077, Loss: 1.2366\n","Epoch: 078, Loss: 1.2313\n","Epoch: 079, Loss: 1.2309\n","Epoch: 080, Loss: 1.2411\n","Epoch: 081, Loss: 1.2215\n","Epoch: 082, Loss: 1.2195\n","Epoch: 083, Loss: 1.2035\n","Epoch: 084, Loss: 1.2055\n","Epoch: 085, Loss: 1.2052\n","Epoch: 086, Loss: 1.1896\n","Epoch: 087, Loss: 1.1974\n","Epoch: 088, Loss: 1.1848\n","Epoch: 089, Loss: 1.1623\n","Epoch: 090, Loss: 1.1649\n","Epoch: 091, Loss: 1.1586\n","Epoch: 092, Loss: 1.1620\n","Epoch: 093, Loss: 1.1611\n","Epoch: 094, Loss: 1.1470\n","Epoch: 095, Loss: 1.1444\n","Epoch: 096, Loss: 1.1492\n","Epoch: 097, Loss: 1.1527\n","Epoch: 098, Loss: 1.1116\n","Epoch: 099, Loss: 1.1310\n","Epoch: 100, Loss: 1.1081\n","Epoch: 101, Loss: 1.1127\n","Epoch: 102, Loss: 1.1183\n","Epoch: 103, Loss: 1.1239\n","Epoch: 104, Loss: 1.1073\n","Epoch: 105, Loss: 1.0977\n","Epoch: 106, Loss: 1.0977\n","Epoch: 107, Loss: 1.0854\n","Epoch: 108, Loss: 1.0791\n","Epoch: 109, Loss: 1.0739\n","Epoch: 110, Loss: 1.0791\n","Epoch: 111, Loss: 1.0797\n","Epoch: 112, Loss: 1.0891\n","Epoch: 113, Loss: 1.0771\n","Epoch: 114, Loss: 1.0684\n","Epoch: 115, Loss: 1.0776\n","Epoch: 116, Loss: 1.0606\n","Epoch: 117, Loss: 1.0612\n","Epoch: 118, Loss: 1.0475\n","Epoch: 119, Loss: 1.0418\n","Epoch: 120, Loss: 1.0477\n","Epoch: 121, Loss: 1.0390\n","Epoch: 122, Loss: 1.0459\n","Epoch: 123, Loss: 1.0458\n","Epoch: 124, Loss: 1.0346\n","Epoch: 125, Loss: 1.0365\n","Epoch: 126, Loss: 1.0049\n","Epoch: 127, Loss: 1.0126\n","Epoch: 128, Loss: 1.0130\n","Epoch: 129, Loss: 1.0176\n","Epoch: 130, Loss: 1.0165\n","Epoch: 131, Loss: 0.9935\n","Epoch: 132, Loss: 1.0027\n","Epoch: 133, Loss: 1.0122\n","Epoch: 134, Loss: 0.9853\n","Epoch: 135, Loss: 1.0099\n","Epoch: 136, Loss: 0.9882\n","Epoch: 137, Loss: 0.9949\n","Epoch: 138, Loss: 1.0043\n","Epoch: 139, Loss: 1.0099\n","Epoch: 140, Loss: 0.9794\n","Epoch: 141, Loss: 0.9981\n","Epoch: 142, Loss: 0.9768\n","Epoch: 143, Loss: 0.9688\n","Epoch: 144, Loss: 0.9829\n","Epoch: 145, Loss: 0.9700\n","Epoch: 146, Loss: 0.9666\n","Epoch: 147, Loss: 0.9690\n","Epoch: 148, Loss: 0.9670\n","Epoch: 149, Loss: 0.9719\n","Epoch: 150, Loss: 0.9463\n","Epoch: 151, Loss: 0.9729\n","Epoch: 152, Loss: 0.9603\n","Epoch: 153, Loss: 0.9766\n","Epoch: 154, Loss: 0.9642\n","Epoch: 155, Loss: 0.9600\n","Epoch: 156, Loss: 0.9467\n","Epoch: 157, Loss: 0.9576\n","Epoch: 158, Loss: 0.9304\n","Epoch: 159, Loss: 0.9605\n","Epoch: 160, Loss: 0.9514\n","Epoch: 161, Loss: 0.9297\n","Epoch: 162, Loss: 0.9461\n","Epoch: 163, Loss: 0.9380\n","Epoch: 164, Loss: 0.9300\n","Epoch: 165, Loss: 0.9435\n","Epoch: 166, Loss: 0.9457\n","Epoch: 167, Loss: 0.9308\n","Epoch: 168, Loss: 0.9276\n","Epoch: 169, Loss: 0.9349\n","Epoch: 170, Loss: 0.9088\n","Epoch: 171, Loss: 0.9418\n","Epoch: 172, Loss: 0.9286\n","Epoch: 173, Loss: 0.9218\n","Epoch: 174, Loss: 0.9126\n","Epoch: 175, Loss: 0.9295\n","Epoch: 176, Loss: 0.9129\n","Epoch: 177, Loss: 0.9012\n","Epoch: 178, Loss: 0.9227\n","Epoch: 179, Loss: 0.9344\n","Epoch: 180, Loss: 0.8973\n","Epoch: 181, Loss: 0.9156\n","Epoch: 182, Loss: 0.9097\n","Epoch: 183, Loss: 0.9123\n","Epoch: 184, Loss: 0.8984\n","Epoch: 185, Loss: 0.8944\n","Epoch: 186, Loss: 0.8898\n","Epoch: 187, Loss: 0.8945\n","Epoch: 188, Loss: 0.9128\n","Epoch: 189, Loss: 0.9122\n","Epoch: 190, Loss: 0.8939\n","Epoch: 191, Loss: 0.8894\n","Epoch: 192, Loss: 0.8968\n","Epoch: 193, Loss: 0.8920\n","Epoch: 194, Loss: 0.8919\n","Epoch: 195, Loss: 0.8978\n","Epoch: 196, Loss: 0.8892\n","Epoch: 197, Loss: 0.8899\n","Epoch: 198, Loss: 0.9065\n","Epoch: 199, Loss: 0.8728\n","Epoch: 200, Loss: 0.8612\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0tNtjYH3Coi6","executionInfo":{"status":"ok","timestamp":1644331713394,"user_tz":-60,"elapsed":235,"user":{"displayName":"Adrian Hernandez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjcBgwUm3IOIr2eMtDO7J2Z0-Ezy0aPy2YzerW1FA=s64","userId":"05338976519150686624"}},"outputId":"533d242d-f0bd-44b7-980a-eeb1037b6333"},"source":["test_acc = test()\n","print(f'Test Accuracy: {test_acc:.4f}')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Test Accuracy: 0.7690\n"]}]},{"cell_type":"markdown","metadata":{"id":"7mTfEBLzzxlj"},"source":["When the first 620 nodes are used for training the GCN to avoid overfitting, we get a test accuracy of 77% (training loss of 0.6831). Training set-test accuracy: 50 nodes-62.1%, 70 nodes-63.6%, 120 nodes-71.4%, 400 nodes-77%, 500 nodes-77.3%, 620 nodes-77%, 800 nodes-76.80%, 1000 nodes-76.2%, 1500 nodes-76.9%. Using the validation mask to train, we get a test accuracy of 76.2% (the training loss is 0.62)."]}]}