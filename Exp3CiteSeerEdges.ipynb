{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Exp3CiteSeerEdges.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMOtsIYfQ2FjlwATWomYlJQ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fYvxMt6P-g8e","executionInfo":{"status":"ok","timestamp":1644624732309,"user_tz":-60,"elapsed":9746,"user":{"displayName":"Adrian Hernandez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjcBgwUm3IOIr2eMtDO7J2Z0-Ezy0aPy2YzerW1FA=s64","userId":"05338976519150686624"}},"outputId":"7de82148-e188-4e39-e4f4-e81301d97962"},"source":["#Check the PyTorch and Cuda version\n","!python -c \"import torch; print(torch.__version__)\"\n","!python -c \"import torch; print(torch.version.cuda)\""],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["1.10.0+cu111\n","11.1\n"]}]},{"cell_type":"code","metadata":{"id":"ICFCAiNp-qHq"},"source":["!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-1.10.0+cu111.html\n","!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-1.10.0+cu111.html\n","!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git\n","!pip install torch-cluster -f https://data.pyg.org/whl/torch-1.10.0+cu111.html\n","!pip install torch-spline-conv -f https://pytorch-geometric.com/whl/torch-1.10.0+cu111.html"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LgzQTkyL-4GJ","executionInfo":{"status":"ok","timestamp":1644624777653,"user_tz":-60,"elapsed":5221,"user":{"displayName":"Adrian Hernandez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjcBgwUm3IOIr2eMtDO7J2Z0-Ezy0aPy2YzerW1FA=s64","userId":"05338976519150686624"}},"outputId":"6fae41a6-5509-4bfd-e361-7c9a1979b460"},"source":["#First data characteristics\n","from torch_geometric.datasets import Planetoid\n","from torch_geometric.transforms import NormalizeFeatures\n","\n","dataset = Planetoid(root='/tmp/CiteSeer', name='CiteSeer',transform=NormalizeFeatures())\n","\n","data = dataset[0]\n","print(data)\n","\n","print(f'Number of nodes: {data.num_nodes}')\n","print(f'Nodes features: {data.num_node_features}')\n","print(f'Number of classes: {dataset.num_classes}')\n","print(f'Number of edges: {data.num_edges}')\n","print(f'Avarage degree: {data.num_edges / data.num_nodes:.2f}')\n","print(f'Training nodes: {data.train_mask.sum()}')\n","print(f'Validation nodes: {data.val_mask.sum()}')\n","print(f'Test nodes: {data.test_mask.sum()}')\n","print(f'Isolated nodes: {data.has_isolated_nodes()}')\n","print(f'Loops: {data.has_self_loops()}')\n","print(f'Is undirected: {data.is_undirected()}')"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.x\n","Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.tx\n","Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.allx\n","Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.y\n","Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.ty\n","Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.ally\n","Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.graph\n","Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.test.index\n","Processing...\n"]},{"output_type":"stream","name":"stdout","text":["Data(x=[3327, 3703], edge_index=[2, 9104], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327])\n","Number of nodes: 3327\n","Nodes features: 3703\n","Number of classes: 6\n","Number of edges: 9104\n","Avarage degree: 2.74\n","Training nodes: 120\n","Validation nodes: 500\n","Test nodes: 1000\n","Isolated nodes: True\n","Loops: False\n","Is undirected: True\n"]},{"output_type":"stream","name":"stderr","text":["Done!\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HPY9YcNiXoxL","executionInfo":{"status":"ok","timestamp":1644624853429,"user_tz":-60,"elapsed":255,"user":{"displayName":"Adrian Hernandez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjcBgwUm3IOIr2eMtDO7J2Z0-Ezy0aPy2YzerW1FA=s64","userId":"05338976519150686624"}},"outputId":"44c47661-b39f-478b-8a71-746174b8662d"},"source":["#We create the same number of edges but in a random way between the [0..3326] nodes\n","#Citeseer network is undirected, then the edges appear twice (i,j) (j,i) in the original edge matrix\n","#In this random edge matrix, the edges are directed\n","import torch\n","\n","edge_index1=torch.randint(0,3327,(2,9104))\n","print(edge_index1)\n","edge_index1[:,1]"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[1176, 3153, 1276,  ..., 2158, 2853,  444],\n","        [   7,  366, 1837,  ..., 1510, 2961,  428]])\n"]},{"output_type":"execute_result","data":{"text/plain":["tensor([3153,  366])"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-PlIBdNEhhuV","executionInfo":{"status":"ok","timestamp":1644624856148,"user_tz":-60,"elapsed":7,"user":{"displayName":"Adrian Hernandez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjcBgwUm3IOIr2eMtDO7J2Z0-Ezy0aPy2YzerW1FA=s64","userId":"05338976519150686624"}},"outputId":"e651312d-6008-4566-bd38-ee09acb3c720"},"source":["#Checkin boolean tensors to select tensor items\n","check=torch.rand(6)\n","print(check)\n","\n","true=torch.tensor([True, False, True, False, True, False])\n","check[true]"],"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([0.5217, 0.6586, 0.2691, 0.7446, 0.2061, 0.1023])\n"]},{"output_type":"execute_result","data":{"text/plain":["tensor([0.5217, 0.2691, 0.2061])"]},"metadata":{},"execution_count":5}]},{"cell_type":"markdown","metadata":{"id":"aOesxumADWtu"},"source":["**Model with GCN modifying the edges information (random edges)**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3Wt9BL5YBUlg","executionInfo":{"status":"ok","timestamp":1644624859088,"user_tz":-60,"elapsed":302,"user":{"displayName":"Adrian Hernandez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjcBgwUm3IOIr2eMtDO7J2Z0-Ezy0aPy2YzerW1FA=s64","userId":"05338976519150686624"}},"outputId":"ef93ea2c-c0f5-4097-8005-9d1f44fb5d86"},"source":["import torch\n","from torch.nn import Linear\n","import torch.nn.functional as F\n","from torch_geometric.nn import GCNConv\n","\n","\n","\n","class GCN(torch.nn.Module):\n","    def __init__(self, hidden_channels):\n","        super(GCN, self).__init__()\n","        torch.manual_seed(1234567)\n","        self.conv1 = GCNConv(dataset.num_features, hidden_channels)\n","        self.conv2 = GCNConv(hidden_channels, dataset.num_classes)\n","\n","    def forward(self, x, edge_index):\n","        x = self.conv1(x, edge_index)\n","        x = x.relu()\n","        x = F.dropout(x, p=0.5, training=self.training)\n","        x = self.conv2(x, edge_index)\n","        return x\n","\n","model = GCN(hidden_channels=16)\n","\n","def model_summary(model):\n","    \n","    model_params_list = list(model.named_parameters())\n","    print(\"----------------------------------------------------------------\")\n","    line_new = \"{:>20}  {:>25} {:>15}\".format(\"Layer.Parameter\", \"Param Tensor Shape\", \"Param #\")\n","    print(line_new)\n","    print(\"----------------------------------------------------------------\")\n","    for elem in model_params_list:\n","        p_name = elem[0] \n","        p_shape = list(elem[1].size())\n","        p_count = torch.tensor(elem[1].size()).prod().item()\n","        line_new = \"{:>20}  {:>25} {:>15}\".format(p_name, str(p_shape), str(p_count))\n","        print(line_new)\n","    print(\"----------------------------------------------------------------\")\n","    total_params = sum([param.nelement() for param in model.parameters()])\n","    print(\"Total params:\", total_params)\n","    num_trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n","    print(\"Trainable params:\", num_trainable_params)\n","    print(\"Non-trainable params:\", total_params - num_trainable_params)\n","\n","model_summary(model)"],"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["----------------------------------------------------------------\n","     Layer.Parameter         Param Tensor Shape         Param #\n","----------------------------------------------------------------\n","          conv1.bias                       [16]              16\n","    conv1.lin.weight                 [16, 3703]           59248\n","          conv2.bias                        [6]               6\n","    conv2.lin.weight                    [6, 16]              96\n","----------------------------------------------------------------\n","Total params: 59366\n","Trainable params: 59366\n","Non-trainable params: 0\n"]}]},{"cell_type":"code","metadata":{"id":"X1JRgje7BZNi","colab":{"base_uri":"https://localhost:8080/","height":300},"executionInfo":{"status":"ok","timestamp":1644624875560,"user_tz":-60,"elapsed":8311,"user":{"displayName":"Adrian Hernandez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjcBgwUm3IOIr2eMtDO7J2Z0-Ezy0aPy2YzerW1FA=s64","userId":"05338976519150686624"}},"outputId":"b185b475-c408-425f-cf60-c7b965c42154"},"source":["#Passing edge_index1 instead data.edge_index as the edge information\n","from IPython.display import Javascript  # Restrict height of output cell.\n","display(Javascript('''google.colab.output.setIframeHeight(0, true, {maxHeight: 300})'''))\n","\n","model = GCN(hidden_channels=16)\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n","criterion = torch.nn.CrossEntropyLoss()\n","\n","def train():\n","      model.train()\n","      optimizer.zero_grad()  # Clear gradients.\n","      out = model(data.x, edge_index1)  # Perform a single forward pass.\n","      loss = criterion(out[data.train_mask], data.y[data.train_mask])  # Compute the loss solely based on the training nodes.\n","      loss.backward()  # Derive gradients.\n","      optimizer.step()  # Update parameters based on gradients.\n","      return loss\n","\n","def test():\n","      model.eval()\n","      out = model(data.x, edge_index1)\n","      pred = out.argmax(dim=1)  # Use the class with highest probability.\n","      test_correct = pred[data.test_mask] == data.y[data.test_mask]  # Check against ground-truth labels.\n","      test_acc = int(test_correct.sum()) / int(data.test_mask.sum())  # Derive ratio of correct predictions.\n","      return test_acc\n","\n","\n","for epoch in range(1, 201):\n","    loss = train()\n","    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}')"],"execution_count":7,"outputs":[{"output_type":"display_data","data":{"application/javascript":["google.colab.output.setIframeHeight(0, true, {maxHeight: 300})"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch: 001, Loss: 1.7914\n","Epoch: 002, Loss: 1.7884\n","Epoch: 003, Loss: 1.7837\n","Epoch: 004, Loss: 1.7783\n","Epoch: 005, Loss: 1.7764\n","Epoch: 006, Loss: 1.7673\n","Epoch: 007, Loss: 1.7617\n","Epoch: 008, Loss: 1.7516\n","Epoch: 009, Loss: 1.7522\n","Epoch: 010, Loss: 1.7461\n","Epoch: 011, Loss: 1.7350\n","Epoch: 012, Loss: 1.7354\n","Epoch: 013, Loss: 1.7192\n","Epoch: 014, Loss: 1.7225\n","Epoch: 015, Loss: 1.7126\n","Epoch: 016, Loss: 1.7002\n","Epoch: 017, Loss: 1.6942\n","Epoch: 018, Loss: 1.6840\n","Epoch: 019, Loss: 1.6893\n","Epoch: 020, Loss: 1.6766\n","Epoch: 021, Loss: 1.6592\n","Epoch: 022, Loss: 1.6697\n","Epoch: 023, Loss: 1.6567\n","Epoch: 024, Loss: 1.6493\n","Epoch: 025, Loss: 1.6343\n","Epoch: 026, Loss: 1.6184\n","Epoch: 027, Loss: 1.6189\n","Epoch: 028, Loss: 1.6067\n","Epoch: 029, Loss: 1.6144\n","Epoch: 030, Loss: 1.5952\n","Epoch: 031, Loss: 1.5788\n","Epoch: 032, Loss: 1.5850\n","Epoch: 033, Loss: 1.5873\n","Epoch: 034, Loss: 1.5728\n","Epoch: 035, Loss: 1.5586\n","Epoch: 036, Loss: 1.5412\n","Epoch: 037, Loss: 1.5307\n","Epoch: 038, Loss: 1.5492\n","Epoch: 039, Loss: 1.4830\n","Epoch: 040, Loss: 1.5279\n","Epoch: 041, Loss: 1.4703\n","Epoch: 042, Loss: 1.5023\n","Epoch: 043, Loss: 1.4552\n","Epoch: 044, Loss: 1.4520\n","Epoch: 045, Loss: 1.4436\n","Epoch: 046, Loss: 1.4638\n","Epoch: 047, Loss: 1.4428\n","Epoch: 048, Loss: 1.4401\n","Epoch: 049, Loss: 1.4315\n","Epoch: 050, Loss: 1.4065\n","Epoch: 051, Loss: 1.3807\n","Epoch: 052, Loss: 1.4224\n","Epoch: 053, Loss: 1.4322\n","Epoch: 054, Loss: 1.3627\n","Epoch: 055, Loss: 1.3316\n","Epoch: 056, Loss: 1.3661\n","Epoch: 057, Loss: 1.3693\n","Epoch: 058, Loss: 1.3209\n","Epoch: 059, Loss: 1.3406\n","Epoch: 060, Loss: 1.3153\n","Epoch: 061, Loss: 1.3036\n","Epoch: 062, Loss: 1.2882\n","Epoch: 063, Loss: 1.2962\n","Epoch: 064, Loss: 1.2810\n","Epoch: 065, Loss: 1.2399\n","Epoch: 066, Loss: 1.2488\n","Epoch: 067, Loss: 1.2492\n","Epoch: 068, Loss: 1.2514\n","Epoch: 069, Loss: 1.1951\n","Epoch: 070, Loss: 1.2774\n","Epoch: 071, Loss: 1.2228\n","Epoch: 072, Loss: 1.2355\n","Epoch: 073, Loss: 1.2424\n","Epoch: 074, Loss: 1.2041\n","Epoch: 075, Loss: 1.1688\n","Epoch: 076, Loss: 1.1751\n","Epoch: 077, Loss: 1.1416\n","Epoch: 078, Loss: 1.1789\n","Epoch: 079, Loss: 1.1702\n","Epoch: 080, Loss: 1.1227\n","Epoch: 081, Loss: 1.1421\n","Epoch: 082, Loss: 1.1116\n","Epoch: 083, Loss: 1.1153\n","Epoch: 084, Loss: 1.1505\n","Epoch: 085, Loss: 1.1071\n","Epoch: 086, Loss: 1.0692\n","Epoch: 087, Loss: 1.0588\n","Epoch: 088, Loss: 1.0754\n","Epoch: 089, Loss: 1.0974\n","Epoch: 090, Loss: 1.0701\n","Epoch: 091, Loss: 1.0889\n","Epoch: 092, Loss: 0.9914\n","Epoch: 093, Loss: 1.0800\n","Epoch: 094, Loss: 1.0501\n","Epoch: 095, Loss: 1.0355\n","Epoch: 096, Loss: 0.9484\n","Epoch: 097, Loss: 1.0066\n","Epoch: 098, Loss: 1.0237\n","Epoch: 099, Loss: 0.9770\n","Epoch: 100, Loss: 0.9607\n","Epoch: 101, Loss: 0.9431\n","Epoch: 102, Loss: 0.9825\n","Epoch: 103, Loss: 0.9611\n","Epoch: 104, Loss: 0.8952\n","Epoch: 105, Loss: 0.9566\n","Epoch: 106, Loss: 0.9380\n","Epoch: 107, Loss: 0.9453\n","Epoch: 108, Loss: 0.9240\n","Epoch: 109, Loss: 0.9671\n","Epoch: 110, Loss: 0.9939\n","Epoch: 111, Loss: 0.9447\n","Epoch: 112, Loss: 0.9240\n","Epoch: 113, Loss: 0.8965\n","Epoch: 114, Loss: 0.8857\n","Epoch: 115, Loss: 0.8967\n","Epoch: 116, Loss: 0.9101\n","Epoch: 117, Loss: 0.8893\n","Epoch: 118, Loss: 0.8857\n","Epoch: 119, Loss: 0.8828\n","Epoch: 120, Loss: 0.8598\n","Epoch: 121, Loss: 0.8634\n","Epoch: 122, Loss: 0.8304\n","Epoch: 123, Loss: 0.8776\n","Epoch: 124, Loss: 0.8534\n","Epoch: 125, Loss: 0.8287\n","Epoch: 126, Loss: 0.8370\n","Epoch: 127, Loss: 0.8190\n","Epoch: 128, Loss: 0.7892\n","Epoch: 129, Loss: 0.7858\n","Epoch: 130, Loss: 0.8348\n","Epoch: 131, Loss: 0.8358\n","Epoch: 132, Loss: 0.7421\n","Epoch: 133, Loss: 0.7994\n","Epoch: 134, Loss: 0.7720\n","Epoch: 135, Loss: 0.7574\n","Epoch: 136, Loss: 0.7347\n","Epoch: 137, Loss: 0.7184\n","Epoch: 138, Loss: 0.8283\n","Epoch: 139, Loss: 0.7886\n","Epoch: 140, Loss: 0.7289\n","Epoch: 141, Loss: 0.7507\n","Epoch: 142, Loss: 0.7643\n","Epoch: 143, Loss: 0.7030\n","Epoch: 144, Loss: 0.7076\n","Epoch: 145, Loss: 0.7542\n","Epoch: 146, Loss: 0.7630\n","Epoch: 147, Loss: 0.7357\n","Epoch: 148, Loss: 0.7836\n","Epoch: 149, Loss: 0.7016\n","Epoch: 150, Loss: 0.7281\n","Epoch: 151, Loss: 0.7062\n","Epoch: 152, Loss: 0.7086\n","Epoch: 153, Loss: 0.6983\n","Epoch: 154, Loss: 0.6665\n","Epoch: 155, Loss: 0.6597\n","Epoch: 156, Loss: 0.6894\n","Epoch: 157, Loss: 0.7746\n","Epoch: 158, Loss: 0.6996\n","Epoch: 159, Loss: 0.7147\n","Epoch: 160, Loss: 0.6783\n","Epoch: 161, Loss: 0.6864\n","Epoch: 162, Loss: 0.6509\n","Epoch: 163, Loss: 0.6738\n","Epoch: 164, Loss: 0.6823\n","Epoch: 165, Loss: 0.6364\n","Epoch: 166, Loss: 0.6523\n","Epoch: 167, Loss: 0.6355\n","Epoch: 168, Loss: 0.6203\n","Epoch: 169, Loss: 0.6646\n","Epoch: 170, Loss: 0.6955\n","Epoch: 171, Loss: 0.6390\n","Epoch: 172, Loss: 0.6475\n","Epoch: 173, Loss: 0.6481\n","Epoch: 174, Loss: 0.6386\n","Epoch: 175, Loss: 0.6641\n","Epoch: 176, Loss: 0.6103\n","Epoch: 177, Loss: 0.5989\n","Epoch: 178, Loss: 0.6563\n","Epoch: 179, Loss: 0.5989\n","Epoch: 180, Loss: 0.6202\n","Epoch: 181, Loss: 0.5952\n","Epoch: 182, Loss: 0.5827\n","Epoch: 183, Loss: 0.6126\n","Epoch: 184, Loss: 0.6690\n","Epoch: 185, Loss: 0.6691\n","Epoch: 186, Loss: 0.6130\n","Epoch: 187, Loss: 0.6394\n","Epoch: 188, Loss: 0.6413\n","Epoch: 189, Loss: 0.5994\n","Epoch: 190, Loss: 0.6304\n","Epoch: 191, Loss: 0.5898\n","Epoch: 192, Loss: 0.5952\n","Epoch: 193, Loss: 0.5761\n","Epoch: 194, Loss: 0.5741\n","Epoch: 195, Loss: 0.5982\n","Epoch: 196, Loss: 0.6010\n","Epoch: 197, Loss: 0.5253\n","Epoch: 198, Loss: 0.6177\n","Epoch: 199, Loss: 0.5733\n","Epoch: 200, Loss: 0.5354\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0tNtjYH3Coi6","executionInfo":{"status":"ok","timestamp":1644624879553,"user_tz":-60,"elapsed":343,"user":{"displayName":"Adrian Hernandez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjcBgwUm3IOIr2eMtDO7J2Z0-Ezy0aPy2YzerW1FA=s64","userId":"05338976519150686624"}},"outputId":"b198fe93-258c-4668-8526-0a8ee8218313"},"source":["test_acc = test()\n","print(f'Test Accuracy: {test_acc:.4f}')"],"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Test Accuracy: 0.1720\n"]}]},{"cell_type":"markdown","metadata":{"id":"pk7R6gxwcCzB"},"source":["Using the training mask with a GCN with two graph convolutional layers and random edges between the nodes, the test accuracy is 16.5% versus the 71.4% obtained with the correct edges."]},{"cell_type":"markdown","metadata":{"id":"v_AAyW07zrZ-"},"source":["**Model with GCN modifying the edges information (edge pruning)**"]},{"cell_type":"code","metadata":{"id":"45uQs0kaPJzo","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1644624975437,"user_tz":-60,"elapsed":258,"user":{"displayName":"Adrian Hernandez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjcBgwUm3IOIr2eMtDO7J2Z0-Ezy0aPy2YzerW1FA=s64","userId":"05338976519150686624"}},"outputId":"c73c1f8b-5e2a-40db-b959-ebb94e10c652"},"source":["#Apply torch.idex_select to the original edge_index matrix to remove certain links. \n","#Citeseer network is undirected, then the edges appear twice (i,j) (j,i) in the original edge matrix\n","#In this random edge matrix, the edges that are removed are directed\n","\n","import torch\n","\n","indices = torch.tensor([1])\n","for i in range(2,9104):\n","\n","  a=torch.tensor([i])\n","  if i % 5 == 0: #Change the equal\n","     indices=torch.cat((indices,a),0)\n","\n","\n","edge_index2=torch.index_select(data.edge_index, 1, indices)\n","edge_index2.shape"],"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([2, 1821])"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iGNJj9kA_tO5","executionInfo":{"status":"ok","timestamp":1644624979280,"user_tz":-60,"elapsed":247,"user":{"displayName":"Adrian Hernandez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjcBgwUm3IOIr2eMtDO7J2Z0-Ezy0aPy2YzerW1FA=s64","userId":"05338976519150686624"}},"outputId":"5b3c636a-5dd8-4e4b-8a08-793ba47e9187"},"source":["import torch\n","from torch.nn import Linear\n","import torch.nn.functional as F\n","from torch_geometric.nn import GCNConv\n","\n","\n","\n","class GCN(torch.nn.Module):\n","    def __init__(self, hidden_channels):\n","        super(GCN, self).__init__()\n","        torch.manual_seed(1234567)\n","        self.conv1 = GCNConv(dataset.num_features, hidden_channels)\n","        self.conv2 = GCNConv(hidden_channels, dataset.num_classes)\n","\n","    def forward(self, x, edge_index):\n","        x = self.conv1(x, edge_index)\n","        x = x.relu()\n","        x = F.dropout(x, p=0.5, training=self.training)\n","        x = self.conv2(x, edge_index)\n","        return x\n","\n","model = GCN(hidden_channels=16)\n","\n","def model_summary(model):\n","    \n","    model_params_list = list(model.named_parameters())\n","    print(\"----------------------------------------------------------------\")\n","    line_new = \"{:>20}  {:>25} {:>15}\".format(\"Layer.Parameter\", \"Param Tensor Shape\", \"Param #\")\n","    print(line_new)\n","    print(\"----------------------------------------------------------------\")\n","    for elem in model_params_list:\n","        p_name = elem[0] \n","        p_shape = list(elem[1].size())\n","        p_count = torch.tensor(elem[1].size()).prod().item()\n","        line_new = \"{:>20}  {:>25} {:>15}\".format(p_name, str(p_shape), str(p_count))\n","        print(line_new)\n","    print(\"----------------------------------------------------------------\")\n","    total_params = sum([param.nelement() for param in model.parameters()])\n","    print(\"Total params:\", total_params)\n","    num_trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n","    print(\"Trainable params:\", num_trainable_params)\n","    print(\"Non-trainable params:\", total_params - num_trainable_params)\n","\n","model_summary(model)"],"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["----------------------------------------------------------------\n","     Layer.Parameter         Param Tensor Shape         Param #\n","----------------------------------------------------------------\n","          conv1.bias                       [16]              16\n","    conv1.lin.weight                 [16, 3703]           59248\n","          conv2.bias                        [6]               6\n","    conv2.lin.weight                    [6, 16]              96\n","----------------------------------------------------------------\n","Total params: 59366\n","Trainable params: 59366\n","Non-trainable params: 0\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":300},"id":"ClDLR6dI_yd_","executionInfo":{"status":"ok","timestamp":1644624990057,"user_tz":-60,"elapsed":6304,"user":{"displayName":"Adrian Hernandez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjcBgwUm3IOIr2eMtDO7J2Z0-Ezy0aPy2YzerW1FA=s64","userId":"05338976519150686624"}},"outputId":"94bcf3e4-e9f4-461f-df2c-6929017230ab"},"source":["#Passing edge_index2 instead data.edge_index as the edge information\n","from IPython.display import Javascript  # Restrict height of output cell.\n","display(Javascript('''google.colab.output.setIframeHeight(0, true, {maxHeight: 300})'''))\n","\n","model = GCN(hidden_channels=16)\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n","criterion = torch.nn.CrossEntropyLoss()\n","\n","def train():\n","      model.train()\n","      optimizer.zero_grad()  # Clear gradients.\n","      out = model(data.x, edge_index2)  # Perform a single forward pass.\n","      loss = criterion(out[data.train_mask], data.y[data.train_mask])  # Compute the loss solely based on the training nodes.\n","      loss.backward()  # Derive gradients.\n","      optimizer.step()  # Update parameters based on gradients.\n","      return loss\n","\n","def test():\n","      model.eval()\n","      out = model(data.x, edge_index2)\n","      pred = out.argmax(dim=1)  # Use the class with highest probability.\n","      test_correct = pred[data.test_mask] == data.y[data.test_mask]  # Check against ground-truth labels.\n","      test_acc = int(test_correct.sum()) / int(data.test_mask.sum())  # Derive ratio of correct predictions.\n","      return test_acc\n","\n","\n","for epoch in range(1, 201):\n","    loss = train()\n","    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}')"],"execution_count":11,"outputs":[{"output_type":"display_data","data":{"application/javascript":["google.colab.output.setIframeHeight(0, true, {maxHeight: 300})"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch: 001, Loss: 1.7915\n","Epoch: 002, Loss: 1.7853\n","Epoch: 003, Loss: 1.7777\n","Epoch: 004, Loss: 1.7656\n","Epoch: 005, Loss: 1.7606\n","Epoch: 006, Loss: 1.7410\n","Epoch: 007, Loss: 1.7268\n","Epoch: 008, Loss: 1.7167\n","Epoch: 009, Loss: 1.7015\n","Epoch: 010, Loss: 1.6918\n","Epoch: 011, Loss: 1.6771\n","Epoch: 012, Loss: 1.6528\n","Epoch: 013, Loss: 1.6261\n","Epoch: 014, Loss: 1.6118\n","Epoch: 015, Loss: 1.5992\n","Epoch: 016, Loss: 1.5798\n","Epoch: 017, Loss: 1.5503\n","Epoch: 018, Loss: 1.5218\n","Epoch: 019, Loss: 1.5065\n","Epoch: 020, Loss: 1.4946\n","Epoch: 021, Loss: 1.4532\n","Epoch: 022, Loss: 1.4516\n","Epoch: 023, Loss: 1.4396\n","Epoch: 024, Loss: 1.4068\n","Epoch: 025, Loss: 1.3721\n","Epoch: 026, Loss: 1.3558\n","Epoch: 027, Loss: 1.3307\n","Epoch: 028, Loss: 1.3468\n","Epoch: 029, Loss: 1.3008\n","Epoch: 030, Loss: 1.2704\n","Epoch: 031, Loss: 1.2093\n","Epoch: 032, Loss: 1.2031\n","Epoch: 033, Loss: 1.1897\n","Epoch: 034, Loss: 1.1788\n","Epoch: 035, Loss: 1.1419\n","Epoch: 036, Loss: 1.0673\n","Epoch: 037, Loss: 1.1066\n","Epoch: 038, Loss: 1.0952\n","Epoch: 039, Loss: 1.0542\n","Epoch: 040, Loss: 1.0819\n","Epoch: 041, Loss: 1.0035\n","Epoch: 042, Loss: 1.0309\n","Epoch: 043, Loss: 0.9361\n","Epoch: 044, Loss: 0.9159\n","Epoch: 045, Loss: 0.8990\n","Epoch: 046, Loss: 0.9538\n","Epoch: 047, Loss: 0.8647\n","Epoch: 048, Loss: 0.8510\n","Epoch: 049, Loss: 0.8661\n","Epoch: 050, Loss: 0.8388\n","Epoch: 051, Loss: 0.8574\n","Epoch: 052, Loss: 0.8100\n","Epoch: 053, Loss: 0.8157\n","Epoch: 054, Loss: 0.7812\n","Epoch: 055, Loss: 0.8076\n","Epoch: 056, Loss: 0.7774\n","Epoch: 057, Loss: 0.8329\n","Epoch: 058, Loss: 0.7139\n","Epoch: 059, Loss: 0.7431\n","Epoch: 060, Loss: 0.6778\n","Epoch: 061, Loss: 0.7266\n","Epoch: 062, Loss: 0.6658\n","Epoch: 063, Loss: 0.6646\n","Epoch: 064, Loss: 0.6655\n","Epoch: 065, Loss: 0.6748\n","Epoch: 066, Loss: 0.6369\n","Epoch: 067, Loss: 0.6381\n","Epoch: 068, Loss: 0.5894\n","Epoch: 069, Loss: 0.6162\n","Epoch: 070, Loss: 0.6284\n","Epoch: 071, Loss: 0.6199\n","Epoch: 072, Loss: 0.6146\n","Epoch: 073, Loss: 0.5819\n","Epoch: 074, Loss: 0.6147\n","Epoch: 075, Loss: 0.5767\n","Epoch: 076, Loss: 0.6045\n","Epoch: 077, Loss: 0.5533\n","Epoch: 078, Loss: 0.5763\n","Epoch: 079, Loss: 0.5330\n","Epoch: 080, Loss: 0.5519\n","Epoch: 081, Loss: 0.5175\n","Epoch: 082, Loss: 0.5706\n","Epoch: 083, Loss: 0.5641\n","Epoch: 084, Loss: 0.5881\n","Epoch: 085, Loss: 0.5061\n","Epoch: 086, Loss: 0.5122\n","Epoch: 087, Loss: 0.4940\n","Epoch: 088, Loss: 0.5271\n","Epoch: 089, Loss: 0.5446\n","Epoch: 090, Loss: 0.5381\n","Epoch: 091, Loss: 0.5835\n","Epoch: 092, Loss: 0.4785\n","Epoch: 093, Loss: 0.5368\n","Epoch: 094, Loss: 0.4640\n","Epoch: 095, Loss: 0.4792\n","Epoch: 096, Loss: 0.5071\n","Epoch: 097, Loss: 0.5130\n","Epoch: 098, Loss: 0.4458\n","Epoch: 099, Loss: 0.4641\n","Epoch: 100, Loss: 0.4630\n","Epoch: 101, Loss: 0.4198\n","Epoch: 102, Loss: 0.4715\n","Epoch: 103, Loss: 0.4196\n","Epoch: 104, Loss: 0.4684\n","Epoch: 105, Loss: 0.4734\n","Epoch: 106, Loss: 0.4548\n","Epoch: 107, Loss: 0.4623\n","Epoch: 108, Loss: 0.4644\n","Epoch: 109, Loss: 0.4523\n","Epoch: 110, Loss: 0.5078\n","Epoch: 111, Loss: 0.4695\n","Epoch: 112, Loss: 0.4448\n","Epoch: 113, Loss: 0.4755\n","Epoch: 114, Loss: 0.4214\n","Epoch: 115, Loss: 0.4869\n","Epoch: 116, Loss: 0.4283\n","Epoch: 117, Loss: 0.4367\n","Epoch: 118, Loss: 0.4631\n","Epoch: 119, Loss: 0.4340\n","Epoch: 120, Loss: 0.4148\n","Epoch: 121, Loss: 0.4206\n","Epoch: 122, Loss: 0.3987\n","Epoch: 123, Loss: 0.4307\n","Epoch: 124, Loss: 0.4500\n","Epoch: 125, Loss: 0.4183\n","Epoch: 126, Loss: 0.4312\n","Epoch: 127, Loss: 0.4254\n","Epoch: 128, Loss: 0.3834\n","Epoch: 129, Loss: 0.3734\n","Epoch: 130, Loss: 0.4127\n","Epoch: 131, Loss: 0.4170\n","Epoch: 132, Loss: 0.3301\n","Epoch: 133, Loss: 0.4045\n","Epoch: 134, Loss: 0.3756\n","Epoch: 135, Loss: 0.4153\n","Epoch: 136, Loss: 0.4055\n","Epoch: 137, Loss: 0.3458\n","Epoch: 138, Loss: 0.4071\n","Epoch: 139, Loss: 0.4371\n","Epoch: 140, Loss: 0.4248\n","Epoch: 141, Loss: 0.3624\n","Epoch: 142, Loss: 0.3832\n","Epoch: 143, Loss: 0.4127\n","Epoch: 144, Loss: 0.3655\n","Epoch: 145, Loss: 0.4142\n","Epoch: 146, Loss: 0.3811\n","Epoch: 147, Loss: 0.3882\n","Epoch: 148, Loss: 0.4070\n","Epoch: 149, Loss: 0.3943\n","Epoch: 150, Loss: 0.3612\n","Epoch: 151, Loss: 0.3638\n","Epoch: 152, Loss: 0.3729\n","Epoch: 153, Loss: 0.4143\n","Epoch: 154, Loss: 0.3521\n","Epoch: 155, Loss: 0.4149\n","Epoch: 156, Loss: 0.3373\n","Epoch: 157, Loss: 0.4392\n","Epoch: 158, Loss: 0.4043\n","Epoch: 159, Loss: 0.3829\n","Epoch: 160, Loss: 0.3416\n","Epoch: 161, Loss: 0.3656\n","Epoch: 162, Loss: 0.3668\n","Epoch: 163, Loss: 0.3955\n","Epoch: 164, Loss: 0.3682\n","Epoch: 165, Loss: 0.3807\n","Epoch: 166, Loss: 0.3641\n","Epoch: 167, Loss: 0.3382\n","Epoch: 168, Loss: 0.3088\n","Epoch: 169, Loss: 0.3308\n","Epoch: 170, Loss: 0.3595\n","Epoch: 171, Loss: 0.3579\n","Epoch: 172, Loss: 0.3404\n","Epoch: 173, Loss: 0.3396\n","Epoch: 174, Loss: 0.3631\n","Epoch: 175, Loss: 0.3825\n","Epoch: 176, Loss: 0.3602\n","Epoch: 177, Loss: 0.3244\n","Epoch: 178, Loss: 0.3377\n","Epoch: 179, Loss: 0.3201\n","Epoch: 180, Loss: 0.3237\n","Epoch: 181, Loss: 0.3732\n","Epoch: 182, Loss: 0.3388\n","Epoch: 183, Loss: 0.3334\n","Epoch: 184, Loss: 0.3616\n","Epoch: 185, Loss: 0.3547\n","Epoch: 186, Loss: 0.3576\n","Epoch: 187, Loss: 0.3171\n","Epoch: 188, Loss: 0.3245\n","Epoch: 189, Loss: 0.3192\n","Epoch: 190, Loss: 0.3344\n","Epoch: 191, Loss: 0.3086\n","Epoch: 192, Loss: 0.3650\n","Epoch: 193, Loss: 0.3382\n","Epoch: 194, Loss: 0.3186\n","Epoch: 195, Loss: 0.3267\n","Epoch: 196, Loss: 0.3622\n","Epoch: 197, Loss: 0.2919\n","Epoch: 198, Loss: 0.3512\n","Epoch: 199, Loss: 0.3313\n","Epoch: 200, Loss: 0.3096\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2fBZidagAdm6","executionInfo":{"status":"ok","timestamp":1644624993702,"user_tz":-60,"elapsed":285,"user":{"displayName":"Adrian Hernandez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjcBgwUm3IOIr2eMtDO7J2Z0-Ezy0aPy2YzerW1FA=s64","userId":"05338976519150686624"}},"outputId":"77e0ba82-baba-46d9-a96c-0026eb735843"},"source":["test_acc = test()\n","print(f'Test Accuracy: {test_acc:.4f}')"],"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Test Accuracy: 0.5920\n"]}]},{"cell_type":"markdown","metadata":{"id":"9bqLCZimAhIK"},"source":["Using the training mask with an GCN intermediate layer and removing a % of the edges gives a test accuracy (20% removed, 67.7%)(25% removed, 68.7%)(33% removed, 67.1%)(50% removed, 68.1 %)(66% removed, 62%)(75% removed, 61.1%)(80% removed, 59.2%) versus the 71.4% obtained with the correct edges and the 58% of the one intermediate layer neural network."]}]}